{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecb9385",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0115eaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imdlib in /opt/anaconda3/lib/python3.12/site-packages (0.1.20)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (3.9.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (2.2.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (2024.1)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (2.2.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (1.13.1)\n",
      "Requirement already satisfied: xarray in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (2023.6.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from imdlib) (2.32.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->imdlib) (3.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->imdlib) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->imdlib) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->imdlib) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->imdlib) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "%pip install imdlib\n",
    "import imdlib as imd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee233fc3",
   "metadata": {},
   "source": [
    "## Define parameters for data loading here, so that if data has already been dowloaded into respective directories only this and block with imd.open_data need to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0faf12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "start_yr = 2020\n",
    "end_yr = 2023\n",
    "\n",
    "# Define the target directory for rainfall data\n",
    "rainfall_target_dir = './imd_data/rain'\n",
    "\n",
    "# Define the target directory for rainfall data\n",
    "tmin_target_dir = './imd_data/tmin'\n",
    "\n",
    "# Define the target directory for rainfall data\n",
    "tmax_target_dir = './imd_data/tmax'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a8b534",
   "metadata": {},
   "source": [
    "## Download data from imdlib\n",
    "This downloads all data to the working directory ('./') because I was having issues putting it in specific folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a20515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import imdlib as imd\n",
    "\n",
    "\n",
    "# Define directories for each variable\n",
    "directories = {\n",
    "    'rain': './imd_data/rain',\n",
    "    'tmin': './imd_data/tmin',\n",
    "    'tmax': './imd_data/tmax'\n",
    "}\n",
    "\n",
    "# Ensure directories exist\n",
    "for directory in directories.values():\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Step 1: Download data to the current directory\n",
    "for variable in directories.keys():\n",
    "    imd.get_data(variable, start_yr=start_yr, end_yr=end_yr, file_dir='.')  # Use current directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33424a",
   "metadata": {},
   "source": [
    "## Move data to specified folder depending on the file name\n",
    "I was having issues with the download just going in the './' directory no matter what I put as file_dir, so this manually moves the data files to their correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89993a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files starting with 'Rainfall' have been moved to: ./imd_data/rain\n",
      "Files starting with 'Mintemp' have been moved to: ./imd_data/tmin\n",
      "Files starting with 'Maxtemp' have been moved to: ./imd_data/tmax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs(rainfall_target_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Step 2: Move files that start with 'Rainfall' to the specified directory\n",
    "for file_name in os.listdir('.'):\n",
    "    if file_name.startswith('Rainfall'):\n",
    "        shutil.move(file_name, os.path.join(rainfall_target_dir, file_name))\n",
    "\n",
    "print(\"Files starting with 'Rainfall' have been moved to:\", rainfall_target_dir)\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(tmin_target_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Step 2: Move files that start with 'Rainfall' to the specified directory\n",
    "for file_name in os.listdir('.'):\n",
    "    if file_name.startswith('Mintemp'):\n",
    "        shutil.move(file_name, os.path.join(tmin_target_dir, file_name))\n",
    "\n",
    "print(\"Files starting with 'Mintemp' have been moved to:\", tmin_target_dir)\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(tmax_target_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Step 2: Move files that start with 'Rainfall' to the specified directory\n",
    "for file_name in os.listdir('.'):\n",
    "    if file_name.startswith('Maxtemp'):\n",
    "        shutil.move(file_name, os.path.join(tmax_target_dir, file_name))\n",
    "\n",
    "print(\"Files starting with 'Maxtemp' have been moved to:\", tmax_target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016a06b",
   "metadata": {},
   "source": [
    "## Load data from the directories into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0320c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load data from the correct directories\n",
    "rain_data = imd.open_data('rain', start_yr, end_yr, file_dir=rainfall_target_dir)\n",
    "tmin_data = imd.open_data('tmin', start_yr, end_yr, file_dir=tmin_target_dir)\n",
    "tmax_data = imd.open_data('tmax', start_yr, end_yr, file_dir=tmax_target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e697c105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.5</td>\n",
       "      <td>67.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.5</td>\n",
       "      <td>69.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.5</td>\n",
       "      <td>70.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404016</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>37.5</td>\n",
       "      <td>93.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404017</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>37.5</td>\n",
       "      <td>94.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404018</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>37.5</td>\n",
       "      <td>95.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404019</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>37.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404020</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>37.5</td>\n",
       "      <td>97.5</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1404021 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time   lat   lon       tmax\n",
       "0       2020-01-01   7.5  67.5  99.900002\n",
       "1       2020-01-01   7.5  68.5  99.900002\n",
       "2       2020-01-01   7.5  69.5  99.900002\n",
       "3       2020-01-01   7.5  70.5  99.900002\n",
       "4       2020-01-01   7.5  71.5  99.900002\n",
       "...            ...   ...   ...        ...\n",
       "1404016 2023-12-31  37.5  93.5  99.900002\n",
       "1404017 2023-12-31  37.5  94.5  99.900002\n",
       "1404018 2023-12-31  37.5  95.5  99.900002\n",
       "1404019 2023-12-31  37.5  96.5  99.900002\n",
       "1404020 2023-12-31  37.5  97.5  99.900002\n",
       "\n",
       "[1404021 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert indices to columns\n",
    "rain_df = rain_data.get_xarray().sel(method='nearest').to_dataframe().reset_index()\n",
    "\n",
    "# Convert indices to columns\n",
    "tmin_df = tmin_data.get_xarray().sel(method='nearest').to_dataframe().reset_index()\n",
    "\n",
    "# Convert indices to columns\n",
    "tmax_df = tmax_data.get_xarray().sel(method='nearest').to_dataframe().reset_index()\n",
    "tmax_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0565f",
   "metadata": {},
   "source": [
    "## Combine rain, tmin, and tmax dataframes into one single one based on the Date, Latitute, and Longitude\n",
    "Also drop rows where rainfall = -999. This likely means data is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2784607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>8.5</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.009602</td>\n",
       "      <td>32.337498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>9.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.446286</td>\n",
       "      <td>22.791275</td>\n",
       "      <td>31.402376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>9.5</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.686659</td>\n",
       "      <td>30.923943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>9.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.944002</td>\n",
       "      <td>30.116961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>10.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.587202</td>\n",
       "      <td>28.477583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403940</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>35.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.944666</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403964</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159044</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403965</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>36.5</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.565676</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403966</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>36.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.005513</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403967</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>36.5</td>\n",
       "      <td>75.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.183759</td>\n",
       "      <td>99.900002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451445 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   lat   lon  rainfall       tmin       tmax\n",
       "41      2020-01-01   8.5  77.5       0.0  24.009602  32.337498\n",
       "71      2020-01-01   9.5  76.5  2.446286  22.791275  31.402376\n",
       "72      2020-01-01   9.5  77.5       0.0  22.686659  30.923943\n",
       "73      2020-01-01   9.5  78.5       0.0  21.944002  30.116961\n",
       "102     2020-01-01  10.5  76.5       0.0  19.587202  28.477583\n",
       "...            ...   ...   ...       ...        ...        ...\n",
       "1403940 2023-12-31  35.5  79.5       0.0  -1.944666  99.900002\n",
       "1403964 2023-12-31  36.5  72.5       0.0   0.159044  99.900002\n",
       "1403965 2023-12-31  36.5  73.5       0.0  -1.565676  99.900002\n",
       "1403966 2023-12-31  36.5  74.5       0.0  -1.005513  99.900002\n",
       "1403967 2023-12-31  36.5  75.5       0.0  -0.183759  99.900002\n",
       "\n",
       "[451445 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the datasets\n",
    "combined_df = rain_df.merge(tmin_df, on=['time', 'lat', 'lon'], suffixes=('_rain', '_tmin'))\n",
    "combined_df = combined_df.merge(tmax_df, on=['time', 'lat', 'lon'])\n",
    "combined_df.rename(columns={'temp': 'tmax'}, inplace=True)\n",
    "combined_df.columns = ['date', 'lat', 'lon', 'rainfall', 'tmin', 'tmax']\n",
    "# Replace -999 with NaN for all columns\n",
    "combined_df.replace(-999, pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034801d3",
   "metadata": {},
   "source": [
    "\n",
    "## Graphs/Data Analysis\n",
    "\n",
    "The distribution of rainfall and temperature data to attempt to visualize relationships and identify any evident patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8776aad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualize rainfall and temperature distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(combined_df['rainfall'], bins=30, kde=True)\n",
    "plt.title('Rainfall Distribution')\n",
    "plt.xlabel('Rainfall (mm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot to observe correlation between temperature and rainfall\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(combined_df['tmax'], combined_df['rainfall'], alpha=0.5)\n",
    "plt.title('Rainfall vs Max Temperature')\n",
    "plt.xlabel('Max Temperature (°C)')\n",
    "plt.ylabel('Rainfall (mm)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd0546",
   "metadata": {},
   "source": [
    "## Convert numerical rainfall data into Categorical data. (None: 0, Low: 1-5, moderate: 6-20, high: 21+)\n",
    "Attempted to find splits where each category had a somewhat equal size. 'None' still has the most values by far however causing bias towards it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cab4445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314038\n",
      "72695\n",
      "42794\n",
      "21918\n"
     ]
    }
   ],
   "source": [
    "# Binarize rainfall into categories\n",
    "combined_df['rainfall_category'] = pd.cut(combined_df['rainfall'], bins=[-1, 0, 5, 20, np.inf], labels=['none', 'low', 'moderate', 'high'])\n",
    "print(len(combined_df[combined_df['rainfall_category'] == 'none']))\n",
    "print(len(combined_df[combined_df['rainfall_category'] == 'low']))\n",
    "print(len(combined_df[combined_df['rainfall_category'] == 'moderate']))\n",
    "print(len(combined_df[combined_df['rainfall_category'] == 'high']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f038a",
   "metadata": {},
   "source": [
    "\n",
    "## Model Training and Testing\n",
    "\n",
    "### K-Nearest Neighbors (KNN) Classification\n",
    "\n",
    "Categorize rainfall into low, medium, and high intensity classes (low: 0-10, moderate 10-50, high: 50+). Trained KNN on tmin, tmax, lat, and lon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b46dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.34      0.33      0.33      4383\n",
      "         low       0.35      0.34      0.34     14586\n",
      "    moderate       0.28      0.19      0.23      8488\n",
      "        none       0.84      0.88      0.86     62832\n",
      "\n",
      "    accuracy                           0.70     90289\n",
      "   macro avg       0.45      0.44      0.44     90289\n",
      "weighted avg       0.69      0.70      0.69     90289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X = combined_df[['tmax', 'tmin', 'lat', 'lon']]\n",
    "y = combined_df['rainfall_category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# KNN classification\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c821c",
   "metadata": {},
   "source": [
    "## KNN second attempt\n",
    "Now training KNN on all previous attributes, plus month, day, and lags (which are attributes from the previous measurement/calendar day). Additionally, there was a major imbalance in the data, where the majority of the categories were 'low'. To counter this problem, I resampled the moderate and high to duplicate some of the data for equal sized categories in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b05f04c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.83      0.97      0.90      7255\n",
      "         low       0.87      0.58      0.69      7237\n",
      "    moderate       0.74      0.86      0.80      7317\n",
      "\n",
      "    accuracy                           0.81     21809\n",
      "   macro avg       0.81      0.81      0.80     21809\n",
      "weighted avg       0.81      0.81      0.80     21809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Feature Engineering: Add month, day, and lag features\n",
    "combined_df['month'] = pd.to_datetime(combined_df['date']).dt.month\n",
    "combined_df['day'] = pd.to_datetime(combined_df['date']).dt.day\n",
    "combined_df['rainfall_lag1'] = combined_df['rainfall'].shift(1)\n",
    "combined_df['tmin_lag1'] = combined_df['tmin'].shift(1)\n",
    "combined_df['tmax_lag1'] = combined_df['tmax'].shift(1)\n",
    "\n",
    "# Drop rows with NaN values caused by lag features\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Resample to balance classes\n",
    "df_low = combined_df[combined_df['rainfall_category'] == 'low']\n",
    "df_moderate = combined_df[combined_df['rainfall_category'] == 'moderate']\n",
    "df_high = combined_df[combined_df['rainfall_category'] == 'high']\n",
    "\n",
    "# Upsample the minority classes\n",
    "df_moderate_upsampled = resample(df_moderate, replace=True, n_samples=len(df_low), random_state=42)\n",
    "df_high_upsampled = resample(df_high, replace=True, n_samples=len(df_low), random_state=42)\n",
    "\n",
    "\n",
    "# Combine to create a balanced dataset and shuffle it\n",
    "balanced_df = pd.concat([df_low, df_moderate_upsampled, df_high_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = balanced_df[['tmax', 'tmin', 'lat', 'lon', 'month', 'day', 'rainfall_lag1', 'tmin_lag1', 'tmax_lag1']]\n",
    "y = balanced_df['rainfall_category']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# KNN classification with optimized n_neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f5247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314034\n",
      "72694\n",
      "42794\n",
      "21918\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7788999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.30      0.32      0.31      2208\n",
      "         low       0.34      0.44      0.38      7258\n",
      "    moderate       0.28      0.34      0.31      4325\n",
      "        none       0.91      0.82      0.86     31354\n",
      "\n",
      "    accuracy                           0.69     45145\n",
      "   macro avg       0.46      0.48      0.47     45145\n",
      "weighted avg       0.73      0.69      0.70     45145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\n",
    "# Feature Engineering: Add month, day, and lag features\n",
    "combined_df['month'] = pd.to_datetime(combined_df['date']).dt.month\n",
    "combined_df['day'] = pd.to_datetime(combined_df['date']).dt.day\n",
    "combined_df['rainfall_lag1'] = combined_df['rainfall'].shift(1)\n",
    "combined_df['tmin_lag1'] = combined_df['tmin'].shift(1)\n",
    "combined_df['tmax_lag1'] = combined_df['tmax'].shift(1)\n",
    "combined_df['rainfall_lag2'] = combined_df['rainfall'].shift(2)\n",
    "combined_df['tmin_lag2'] = combined_df['tmin'].shift(2)\n",
    "combined_df['tmax_lag2'] = combined_df['tmax'].shift(2)\n",
    "combined_df['rainfall_lag3'] = combined_df['rainfall'].shift(3)\n",
    "combined_df['tmin_lag3'] = combined_df['tmin'].shift(3)\n",
    "combined_df['tmax_lag3'] = combined_df['tmax'].shift(3)\n",
    "\n",
    "# Drop rows with NaN values caused by lag features\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Split data into training and testing sets (before resampling)\n",
    "X = combined_df[['tmax', 'tmin', 'lat', 'lon', 'month', 'rainfall_lag1', 'tmin_lag1', 'tmax_lag1', 'rainfall_lag2', 'tmin_lag2', 'tmax_lag2', 'rainfall_lag3', 'tmin_lag3', 'tmax_lag3']]\n",
    "y = combined_df['rainfall_category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Resample only on the training set to balance classes\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "df_none = train_df[train_df['rainfall_category'] == 'none']\n",
    "df_low = train_df[train_df['rainfall_category'] == 'low']\n",
    "df_moderate = train_df[train_df['rainfall_category'] == 'moderate']\n",
    "df_high = train_df[train_df['rainfall_category'] == 'high']\n",
    "\n",
    "# Upsample the minority classes in the training set\n",
    "df_low_upsampled = resample(df_low, replace=True, n_samples=len(df_none), random_state=42)\n",
    "df_moderate_upsampled = resample(df_moderate, replace=True, n_samples=len(df_none), random_state=42)\n",
    "df_high_upsampled = resample(df_high, replace=True, n_samples=len(df_none), random_state=42)\n",
    "\n",
    "# Combine to create a balanced training dataset and shuffle it\n",
    "balanced_train_df = pd.concat([df_none, df_low_upsampled, df_moderate_upsampled, df_high_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separate features and target for the balanced training set\n",
    "X_train_balanced = balanced_train_df.drop('rainfall_category', axis=1)\n",
    "y_train_balanced = balanced_train_df['rainfall_category']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# KNN classification with optimized n_neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "knn.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32a4b9",
   "metadata": {},
   "source": [
    "## KNN Attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c09e84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 54\u001b[0m\n\u001b[1;32m     47\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m9\u001b[39m],\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     51\u001b[0m }\n\u001b[1;32m     53\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(KNeighborsClassifier(), param_grid\u001b[38;5;241m=\u001b[39mparams, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train_balanced, y_train_balanced)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Best Model\u001b[39;00m\n\u001b[1;32m     57\u001b[0m knn \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n\u001b[1;32m    919\u001b[0m         X,\n\u001b[1;32m    920\u001b[0m         y,\n\u001b[1;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m )\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:917\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    914\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    916\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 917\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m _score(\n\u001b[1;32m    918\u001b[0m     estimator, X_test, y_test, scorer, score_params_test, error_score\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:982\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[1;32m    980\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, y_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:253\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score(partial(_cached_call, \u001b[38;5;28;01mNone\u001b[39;00m), estimator, X, y_true, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:345\u001b[0m, in \u001b[0;36m_Scorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pos_label()\n\u001b[1;32m    344\u001b[0m response_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_method)\n\u001b[0;32m--> 345\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m method_caller(\n\u001b[1;32m    346\u001b[0m     estimator, response_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, X, pos_label\u001b[38;5;241m=\u001b[39mpos_label\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    349\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:87\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 87\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[1;32m     88\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_response.py:210\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    208\u001b[0m         pos_label \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 210\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m prediction_method(X)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_log_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    213\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m _process_predict_proba(\n\u001b[1;32m    214\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m    215\u001b[0m         target_type\u001b[38;5;241m=\u001b[39mtarget_type,\n\u001b[1;32m    216\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[1;32m    217\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m    218\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:274\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X)\n\u001b[1;32m    276\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    277\u001b[0m _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_base.py:905\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[1;32m    904\u001b[0m         )\n\u001b[0;32m--> 905\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs, prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    906\u001b[0m         delayed(_tree_query_parallel_helper)(\n\u001b[1;32m    907\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree, X[s], n_neighbors, return_distance\n\u001b[1;32m    908\u001b[0m         )\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m gen_even_slices(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], n_jobs)\n\u001b[1;32m    910\u001b[0m     )\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_base.py:705\u001b[0m, in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_query_parallel_helper\u001b[39m(tree, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper for the Parallel calls in KNeighborsMixin.kneighbors.\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m    The Cython method tree.query is not directly picklable by cloudpickle\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m    under PyPy.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Feature Engineering: Add month, day, lag features, and day of year\n",
    "combined_df['month'] = pd.to_datetime(combined_df['date']).dt.month\n",
    "combined_df['day'] = pd.to_datetime(combined_df['date']).dt.day\n",
    "combined_df['day_of_year'] = pd.to_datetime(combined_df['date']).dt.dayofyear\n",
    "combined_df['rainfall_lag1'] = combined_df['rainfall'].shift(1)\n",
    "combined_df['tmin_lag1'] = combined_df['tmin'].shift(1)\n",
    "combined_df['tmax_lag1'] = combined_df['tmax'].shift(1)\n",
    "combined_df['rainfall_lag2'] = combined_df['rainfall'].shift(2)\n",
    "combined_df['tmin_lag2'] = combined_df['tmin'].shift(2)\n",
    "combined_df['tmax_lag2'] = combined_df['tmax'].shift(2)\n",
    "\n",
    "# Drop rows with NaN values caused by lag features\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Clustering Latitude/Longitude into Regions\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "combined_df['region'] = kmeans.fit_predict(combined_df[['lat', 'lon']])\n",
    "\n",
    "# Split data into features and target\n",
    "X = combined_df[['tmax', 'tmin', 'month', 'day', 'day_of_year', 'rainfall_lag1', 'tmin_lag1', 'tmax_lag1',\n",
    "                 'rainfall_lag2', 'tmin_lag2', 'tmax_lag2', 'region']]\n",
    "y = combined_df['rainfall_category']\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Handle Class Imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Try Different Scaling Methods\n",
    "scaler = MinMaxScaler()  # Alternative: StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Perform Grid Search for Hyperparameter Tuning\n",
    "params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=params, cv=5, scoring='accuracy', verbose=1)\n",
    "grid.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best Model\n",
    "knn = grid.best_estimator_\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Cross-Validation Accuracy\n",
    "scores = cross_val_score(knn, X_train_balanced, y_train_balanced, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f5ddd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Feature Engineering: Add month, day, lag features, and day of year\n",
    "combined_df['month'] = pd.to_datetime(combined_df['date']).dt.month\n",
    "combined_df['day'] = pd.to_datetime(combined_df['date']).dt.day\n",
    "combined_df['day_of_year'] = pd.to_datetime(combined_df['date']).dt.dayofyear\n",
    "combined_df['rainfall_lag1'] = combined_df['rainfall'].shift(1)\n",
    "combined_df['tmin_lag1'] = combined_df['tmin'].shift(1)\n",
    "combined_df['tmax_lag1'] = combined_df['tmax'].shift(1)\n",
    "combined_df['rainfall_lag2'] = combined_df['rainfall'].shift(2)\n",
    "combined_df['tmin_lag2'] = combined_df['tmin'].shift(2)\n",
    "combined_df['tmax_lag2'] = combined_df['tmax'].shift(2)\n",
    "\n",
    "# Drop rows with NaN values caused by lag features\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Clustering Latitude/Longitude into Regions\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "combined_df['region'] = kmeans.fit_predict(combined_df[['lat', 'lon']])\n",
    "\n",
    "# Add rolling averages for rainfall and temperature\n",
    "combined_df['rainfall_rolling7'] = combined_df['rainfall'].rolling(window=7).mean()\n",
    "combined_df['tmax_rolling7'] = combined_df['tmax'].rolling(window=7).mean()\n",
    "combined_df['tmin_rolling7'] = combined_df['tmin'].rolling(window=7).mean()\n",
    "\n",
    "# Drop rows with NaN values caused by rolling averages\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Update feature set\n",
    "X = combined_df[['tmax', 'tmin', 'rainfall_rolling7', 'tmax_rolling7', 'tmin_rolling7', \n",
    "                 'month', 'day', 'day_of_year', 'region']]\n",
    "y = combined_df['rainfall_category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d557333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m rf_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), param_grid\u001b[38;5;241m=\u001b[39mrf_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train_balanced, y_train_balanced)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Best Model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m rf \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n\u001b[1;32m    919\u001b[0m         X,\n\u001b[1;32m    920\u001b[0m         y,\n\u001b[1;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m )\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[1;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[1;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Try Random Forest for better performance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_params, cv=5, scoring='accuracy', verbose=1)\n",
    "grid.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best Model\n",
    "rf = grid.best_estimator_\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75533027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-macosx_10_15_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.5.0-py3-none-macosx_10_15_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7342c89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 1130376, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 30, 'min_child_samples': 50, 'n_estimators': 300, 'num_leaves': 70}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.38      0.74      0.50      2193\n",
      "         low       0.40      0.51      0.45      7224\n",
      "    moderate       0.33      0.48      0.39      4293\n",
      "        none       0.97      0.79      0.87     31434\n",
      "\n",
      "    accuracy                           0.71     45144\n",
      "   macro avg       0.52      0.63      0.55     45144\n",
      "weighted avg       0.79      0.71      0.74     45144\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1622    75   485    11]\n",
      " [  869  3713  2040   602]\n",
      " [ 1283   870  2047    93]\n",
      " [  522  4684  1548 24680]]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904300, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 904301, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386295\n",
      "[LightGBM] [Info] Start training from score -1.386291\n",
      "\n",
      "Cross-Validation F1 Macro Score: 0.7132443165004493\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Feature Engineering: Add lag features, rolling averages, and seasonal features\n",
    "combined_df['month'] = pd.to_datetime(combined_df['date']).dt.month\n",
    "combined_df['day'] = pd.to_datetime(combined_df['date']).dt.day\n",
    "combined_df['day_of_year'] = pd.to_datetime(combined_df['date']).dt.dayofyear\n",
    "\n",
    "# Add lag features for rainfall and temperature\n",
    "for lag in range(1, 4):  # Create 3 lag features\n",
    "    combined_df[f'rainfall_lag{lag}'] = combined_df['rainfall'].shift(lag)\n",
    "    combined_df[f'tmin_lag{lag}'] = combined_df['tmin'].shift(lag)\n",
    "    combined_df[f'tmax_lag{lag}'] = combined_df['tmax'].shift(lag)\n",
    "\n",
    "# Add rolling averages\n",
    "combined_df['rainfall_rolling7'] = combined_df['rainfall'].rolling(window=7).mean()\n",
    "combined_df['tmax_rolling7'] = combined_df['tmax'].rolling(window=7).mean()\n",
    "combined_df['tmin_rolling7'] = combined_df['tmin'].rolling(window=7).mean()\n",
    "\n",
    "\n",
    "# Drop rows with NaN values caused by lagging and rolling features\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Clustering Latitude/Longitude into Regions (KMeans)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "combined_df['region'] = kmeans.fit_predict(combined_df[['lat', 'lon']])\n",
    "\n",
    "# Define Features and Target\n",
    "X = combined_df[['tmax', 'tmin', 'rainfall_rolling7', 'tmax_rolling7', 'tmin_rolling7', 'day_of_year', 'region']]\n",
    "y = combined_df['rainfall_category']\n",
    "\n",
    "# Split into Training and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Handle Class Imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# LightGBM Classifier with Hyperparameter Tuning\n",
    "lgbm_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'min_child_samples': [20, 50, 100]\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "grid = GridSearchCV(lgbm, param_grid=lgbm_params, cv=5, scoring='f1_macro', verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best Model\n",
    "best_lgbm = grid.best_estimator_\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "\n",
    "# Evaluate the Best Model\n",
    "y_pred = best_lgbm.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Cross-Validation Score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(best_lgbm, X_train_balanced, y_train_balanced, cv=5, scoring='f1_macro')\n",
    "print(\"\\nCross-Validation F1 Macro Score:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f35623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 30, 'min_child_samples': 50, 'n_estimators': 300, 'num_leaves': 70}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb796d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c6743ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, change: 1.00000000\n",
      "Epoch 2, change: 0.04472426\n",
      "Epoch 3, change: 0.01598814\n",
      "Epoch 4, change: 0.00974481\n",
      "Epoch 5, change: 0.00903399\n",
      "Epoch 6, change: 0.00502258\n",
      "Epoch 7, change: 0.00329183\n",
      "Epoch 8, change: 0.00082156\n",
      "Epoch 9, change: 0.00299354\n",
      "Epoch 10, change: 0.00282960\n",
      "Epoch 11, change: 0.00020037\n",
      "Epoch 12, change: 0.00013768\n",
      "convergence after 13 epochs took 10 seconds\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.30      0.58      0.39      4393\n",
      "         low       0.30      0.41      0.34     14672\n",
      "    moderate       0.30      0.24      0.27      8451\n",
      "        none       0.91      0.79      0.84     62768\n",
      "\n",
      "    accuracy                           0.67     90284\n",
      "   macro avg       0.45      0.51      0.46     90284\n",
      "weighted avg       0.72      0.67      0.69     90284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Split data into training and testing sets (before resampling)\n",
    "X = combined_df[['tmax', 'tmin', 'lat', 'lon', 'month', 'rainfall_lag1', 'tmin_lag1', 'tmax_lag1', 'rainfall_lag2', 'tmin_lag2', 'tmax_lag2', 'rainfall_lag3', 'tmin_lag3', 'tmax_lag3']]\n",
    "y = combined_df['rainfall_category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Resample only on the training set to balance classes\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "df_none = train_df[train_df['rainfall_category'] == 'none']\n",
    "df_low = train_df[train_df['rainfall_category'] == 'low']\n",
    "df_moderate = train_df[train_df['rainfall_category'] == 'moderate']\n",
    "df_high = train_df[train_df['rainfall_category'] == 'high']\n",
    "\n",
    "# Upsample the minority classes in the training set\n",
    "df_low_upsampled = resample(df_low, replace=True, n_samples=len(df_none), random_state=42)\n",
    "df_moderate_upsampled = resample(df_moderate, replace=True, n_samples=len(df_none), random_state=42)\n",
    "df_high_upsampled = resample(df_high, replace=True, n_samples=len(df_none), random_state=42)\n",
    "\n",
    "# Combine to create a balanced training dataset and shuffle it\n",
    "balanced_train_df = pd.concat([df_none, df_low_upsampled, df_moderate_upsampled, df_high_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separate features and target for the balanced training set\n",
    "X_train_balanced = balanced_train_df.drop('rainfall_category', axis=1)\n",
    "y_train_balanced = balanced_train_df['rainfall_category']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train Logistic Regression model with increased max_iter and 'saga' solver\n",
    "log_regression = LogisticRegression(max_iter=500, solver='saga', verbose=True)\n",
    "log_regression.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = log_regression.predict(X_test)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c916594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>rainfall_lag1</th>\n",
       "      <th>tmin_lag1</th>\n",
       "      <th>tmax_lag1</th>\n",
       "      <th>rainfall_lag2</th>\n",
       "      <th>tmin_lag2</th>\n",
       "      <th>tmax_lag2</th>\n",
       "      <th>rainfall_lag3</th>\n",
       "      <th>tmin_lag3</th>\n",
       "      <th>tmax_lag3</th>\n",
       "      <th>rainfall_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308148</th>\n",
       "      <td>24.468172</td>\n",
       "      <td>14.482224</td>\n",
       "      <td>27.5</td>\n",
       "      <td>75.5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.376560</td>\n",
       "      <td>26.026825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.856816</td>\n",
       "      <td>26.467449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.147067</td>\n",
       "      <td>27.592621</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189792</th>\n",
       "      <td>31.170446</td>\n",
       "      <td>22.925371</td>\n",
       "      <td>22.5</td>\n",
       "      <td>77.5</td>\n",
       "      <td>7</td>\n",
       "      <td>9.143746</td>\n",
       "      <td>23.060347</td>\n",
       "      <td>30.848644</td>\n",
       "      <td>16.895939</td>\n",
       "      <td>22.706800</td>\n",
       "      <td>30.492731</td>\n",
       "      <td>6.992356</td>\n",
       "      <td>23.237637</td>\n",
       "      <td>30.964306</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420468</th>\n",
       "      <td>29.564405</td>\n",
       "      <td>16.483616</td>\n",
       "      <td>23.5</td>\n",
       "      <td>82.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.960067</td>\n",
       "      <td>15.632604</td>\n",
       "      <td>30.064024</td>\n",
       "      <td>8.677505</td>\n",
       "      <td>15.744436</td>\n",
       "      <td>31.453554</td>\n",
       "      <td>11.182627</td>\n",
       "      <td>15.337174</td>\n",
       "      <td>31.679895</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497591</th>\n",
       "      <td>27.069975</td>\n",
       "      <td>16.277550</td>\n",
       "      <td>31.5</td>\n",
       "      <td>77.5</td>\n",
       "      <td>6</td>\n",
       "      <td>10.857388</td>\n",
       "      <td>17.239813</td>\n",
       "      <td>29.172094</td>\n",
       "      <td>1.70381</td>\n",
       "      <td>20.610767</td>\n",
       "      <td>32.110329</td>\n",
       "      <td>4.501268</td>\n",
       "      <td>21.542048</td>\n",
       "      <td>33.946007</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282495</th>\n",
       "      <td>29.373991</td>\n",
       "      <td>23.519861</td>\n",
       "      <td>23.5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>8</td>\n",
       "      <td>50.799137</td>\n",
       "      <td>23.568340</td>\n",
       "      <td>29.370785</td>\n",
       "      <td>3.39203</td>\n",
       "      <td>26.455067</td>\n",
       "      <td>34.107105</td>\n",
       "      <td>2.619591</td>\n",
       "      <td>25.403633</td>\n",
       "      <td>34.175896</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643911</th>\n",
       "      <td>29.558029</td>\n",
       "      <td>23.411194</td>\n",
       "      <td>8.5</td>\n",
       "      <td>77.5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.514454</td>\n",
       "      <td>19.850872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.135349</td>\n",
       "      <td>19.743677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.580077</td>\n",
       "      <td>18.865578</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575431</th>\n",
       "      <td>28.582174</td>\n",
       "      <td>21.826008</td>\n",
       "      <td>31.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.217270</td>\n",
       "      <td>30.366285</td>\n",
       "      <td>1.344704</td>\n",
       "      <td>24.913584</td>\n",
       "      <td>32.559273</td>\n",
       "      <td>18.695019</td>\n",
       "      <td>21.341101</td>\n",
       "      <td>26.314484</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307436</th>\n",
       "      <td>29.258955</td>\n",
       "      <td>22.292782</td>\n",
       "      <td>22.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9</td>\n",
       "      <td>32.404373</td>\n",
       "      <td>22.208860</td>\n",
       "      <td>29.757603</td>\n",
       "      <td>67.861443</td>\n",
       "      <td>22.050854</td>\n",
       "      <td>30.273502</td>\n",
       "      <td>0.424304</td>\n",
       "      <td>22.130777</td>\n",
       "      <td>30.191908</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290758</th>\n",
       "      <td>33.298981</td>\n",
       "      <td>25.200878</td>\n",
       "      <td>11.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.02994</td>\n",
       "      <td>21.341215</td>\n",
       "      <td>28.770288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.340857</td>\n",
       "      <td>27.717375</td>\n",
       "      <td>18.252485</td>\n",
       "      <td>21.252438</td>\n",
       "      <td>27.248331</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53335</th>\n",
       "      <td>24.992189</td>\n",
       "      <td>15.602146</td>\n",
       "      <td>22.5</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.941225</td>\n",
       "      <td>14.703054</td>\n",
       "      <td>25.124245</td>\n",
       "      <td>11.45261</td>\n",
       "      <td>14.200025</td>\n",
       "      <td>27.224743</td>\n",
       "      <td>0.492412</td>\n",
       "      <td>13.700701</td>\n",
       "      <td>27.128136</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251247 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tmax       tmin   lat   lon  month rainfall_lag1  tmin_lag1  \\\n",
       "308148   24.468172  14.482224  27.5  75.5     11           0.0  15.376560   \n",
       "189792   31.170446  22.925371  22.5  77.5      7      9.143746  23.060347   \n",
       "420468   29.564405  16.483616  23.5  82.5      3      2.960067  15.632604   \n",
       "497591   27.069975  16.277550  31.5  77.5      6     10.857388  17.239813   \n",
       "1282495  29.373991  23.519861  23.5  92.5      8     50.799137  23.568340   \n",
       "...            ...        ...   ...   ...    ...           ...        ...   \n",
       "643911   29.558029  23.411194   8.5  77.5     11           0.0   5.514454   \n",
       "575431   28.582174  21.826008  31.5  76.5      8           0.0  24.217270   \n",
       "1307436  29.258955  22.292782  22.5  78.5      9     32.404373  22.208860   \n",
       "1290758  33.298981  25.200878  11.5  78.5      9       0.02994  21.341215   \n",
       "53335    24.992189  15.602146  22.5  82.5      2      1.941225  14.703054   \n",
       "\n",
       "         tmax_lag1 rainfall_lag2  tmin_lag2  tmax_lag2 rainfall_lag3  \\\n",
       "308148   26.026825           0.0  14.856816  26.467449           0.0   \n",
       "189792   30.848644     16.895939  22.706800  30.492731      6.992356   \n",
       "420468   30.064024      8.677505  15.744436  31.453554     11.182627   \n",
       "497591   29.172094       1.70381  20.610767  32.110329      4.501268   \n",
       "1282495  29.370785       3.39203  26.455067  34.107105      2.619591   \n",
       "...            ...           ...        ...        ...           ...   \n",
       "643911   19.850872           0.0   5.135349  19.743677           0.0   \n",
       "575431   30.366285      1.344704  24.913584  32.559273     18.695019   \n",
       "1307436  29.757603     67.861443  22.050854  30.273502      0.424304   \n",
       "1290758  28.770288           0.0  20.340857  27.717375     18.252485   \n",
       "53335    25.124245      11.45261  14.200025  27.224743      0.492412   \n",
       "\n",
       "         tmin_lag3  tmax_lag3 rainfall_category  \n",
       "308148   15.147067  27.592621          moderate  \n",
       "189792   23.237637  30.964306          moderate  \n",
       "420468   15.337174  31.679895          moderate  \n",
       "497591   21.542048  33.946007          moderate  \n",
       "1282495  25.403633  34.175896          moderate  \n",
       "...            ...        ...               ...  \n",
       "643911    4.580077  18.865578          moderate  \n",
       "575431   21.341101  26.314484          moderate  \n",
       "1307436  22.130777  30.191908          moderate  \n",
       "1290758  21.252438  27.248331          moderate  \n",
       "53335    13.700701  27.128136          moderate  \n",
       "\n",
       "[251247 rows x 15 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_moderate_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3f9ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.53      0.34      0.41      2165\n",
      "         low       0.44      0.49      0.47      7354\n",
      "    moderate       0.38      0.34      0.36      4216\n",
      "        none       0.90      0.91      0.91     31407\n",
      "\n",
      "    accuracy                           0.76     45142\n",
      "   macro avg       0.56      0.52      0.54     45142\n",
      "weighted avg       0.76      0.76      0.76     45142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Random Forest classification with balanced training data\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a659fe9",
   "metadata": {},
   "source": [
    "\n",
    "### ReLU Neural Network for Regression\n",
    "\n",
    "We will train a ReLU-based neural network to predict daily rainfall amounts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eadf8224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Mean Squared Error: 99.74721447451864\n",
      "Neural Network R-squared: 0.17847668872686462\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets (before resampling)\n",
    "X = combined_df[['tmax', 'tmin', 'lat', 'lon', 'month', 'rainfall_lag1', 'tmin_lag1', 'tmax_lag1', 'rainfall_lag2', 'tmin_lag2', 'tmax_lag2', 'rainfall_lag3', 'tmin_lag3', 'tmax_lag3']]\n",
    "y = combined_df['rainfall']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Resample only on the training set to balance classes\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "df_none = train_df[train_df['rainfall'] <= 0]\n",
    "df_low = train_df[(train_df['rainfall'] >= 1) & (train_df['rainfall'] <= 5)]\n",
    "df_moderate = train_df[(train_df['rainfall'] >= 6) & (train_df['rainfall'] <= 20)]\n",
    "df_high = train_df[train_df['rainfall'] > 20]\n",
    "\n",
    "# Upsample the minority classes in the training set\n",
    "df_low_upsampled = resample(df_low, replace=True, n_samples=len(df_none), random_state=42)\n",
    "df_moderate_upsampled = resample(df_moderate, replace=True, n_samples=len(df_none), random_state=42)\n",
    "df_high_upsampled = resample(df_high, replace=True, n_samples=len(df_none), random_state=42)\n",
    "\n",
    "# Combine to create a balanced training dataset and shuffle it\n",
    "balanced_train_df = pd.concat([df_none, df_low_upsampled, df_moderate_upsampled, df_high_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separate features and target for the balanced training set\n",
    "X_train_balanced = balanced_train_df.drop('rainfall', axis=1)\n",
    "y_train_balanced = balanced_train_df['rainfall']\n",
    "\n",
    "\n",
    "\n",
    "# Neural network regression\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', max_iter=500, random_state=42, verbose=True)\n",
    "mlp.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_nn = mlp.predict(X_test)\n",
    "\n",
    "# Model performance\n",
    "print(\"Neural Network Mean Squared Error:\", mean_squared_error(y_test, y_pred_nn))\n",
    "print(\"Neural Network R-squared:\", r2_score(y_test, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2486a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>rainfall_lag1</th>\n",
       "      <th>tmin_lag1</th>\n",
       "      <th>tmax_lag1</th>\n",
       "      <th>rainfall_lag2</th>\n",
       "      <th>tmin_lag2</th>\n",
       "      <th>tmax_lag2</th>\n",
       "      <th>rainfall_lag3</th>\n",
       "      <th>tmin_lag3</th>\n",
       "      <th>tmax_lag3</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233506</th>\n",
       "      <td>33.500629</td>\n",
       "      <td>25.851522</td>\n",
       "      <td>24.5</td>\n",
       "      <td>83.5</td>\n",
       "      <td>7</td>\n",
       "      <td>11.457508</td>\n",
       "      <td>26.260187</td>\n",
       "      <td>33.184647</td>\n",
       "      <td>6.314296</td>\n",
       "      <td>26.018789</td>\n",
       "      <td>32.774895</td>\n",
       "      <td>20.407169</td>\n",
       "      <td>25.597666</td>\n",
       "      <td>32.858776</td>\n",
       "      <td>4.767361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69912</th>\n",
       "      <td>22.160629</td>\n",
       "      <td>8.690793</td>\n",
       "      <td>30.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.041445</td>\n",
       "      <td>15.788067</td>\n",
       "      <td>30.918373</td>\n",
       "      <td>4.156647</td>\n",
       "      <td>16.041580</td>\n",
       "      <td>30.595781</td>\n",
       "      <td>6.430786</td>\n",
       "      <td>10.608399</td>\n",
       "      <td>19.546478</td>\n",
       "      <td>4.828847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264558</th>\n",
       "      <td>30.699596</td>\n",
       "      <td>19.973892</td>\n",
       "      <td>34.5</td>\n",
       "      <td>73.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.625856</td>\n",
       "      <td>27.753078</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>19.790253</td>\n",
       "      <td>30.207409</td>\n",
       "      <td>2.366238</td>\n",
       "      <td>20.289574</td>\n",
       "      <td>30.420904</td>\n",
       "      <td>1.17993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169046</th>\n",
       "      <td>33.820515</td>\n",
       "      <td>22.628618</td>\n",
       "      <td>22.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.126904</td>\n",
       "      <td>33.892773</td>\n",
       "      <td>0.047061</td>\n",
       "      <td>22.913815</td>\n",
       "      <td>31.883038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.908373</td>\n",
       "      <td>31.278032</td>\n",
       "      <td>1.917958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612102</th>\n",
       "      <td>29.371477</td>\n",
       "      <td>16.738756</td>\n",
       "      <td>36.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>9</td>\n",
       "      <td>6.417793</td>\n",
       "      <td>15.907810</td>\n",
       "      <td>28.610575</td>\n",
       "      <td>7.690259</td>\n",
       "      <td>16.826775</td>\n",
       "      <td>29.499233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.303546</td>\n",
       "      <td>26.999653</td>\n",
       "      <td>1.624089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086996</th>\n",
       "      <td>31.438076</td>\n",
       "      <td>21.369711</td>\n",
       "      <td>10.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.793087</td>\n",
       "      <td>32.266541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.465057</td>\n",
       "      <td>30.515810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.030764</td>\n",
       "      <td>30.152756</td>\n",
       "      <td>4.727511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204381</th>\n",
       "      <td>32.944904</td>\n",
       "      <td>23.809467</td>\n",
       "      <td>27.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>7</td>\n",
       "      <td>5.356512</td>\n",
       "      <td>24.088800</td>\n",
       "      <td>32.993355</td>\n",
       "      <td>2.164036</td>\n",
       "      <td>24.097441</td>\n",
       "      <td>32.973579</td>\n",
       "      <td>9.242778</td>\n",
       "      <td>24.689068</td>\n",
       "      <td>32.823479</td>\n",
       "      <td>2.077559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385186</th>\n",
       "      <td>8.659752</td>\n",
       "      <td>3.233021</td>\n",
       "      <td>32.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>2</td>\n",
       "      <td>6.177868</td>\n",
       "      <td>3.179184</td>\n",
       "      <td>9.396719</td>\n",
       "      <td>6.813626</td>\n",
       "      <td>5.265955</td>\n",
       "      <td>11.882030</td>\n",
       "      <td>4.767539</td>\n",
       "      <td>5.560972</td>\n",
       "      <td>13.384615</td>\n",
       "      <td>3.180301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>4.364387</td>\n",
       "      <td>-6.854029</td>\n",
       "      <td>35.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.430208</td>\n",
       "      <td>-6.226419</td>\n",
       "      <td>5.599256</td>\n",
       "      <td>4.550791</td>\n",
       "      <td>-5.436159</td>\n",
       "      <td>6.039911</td>\n",
       "      <td>4.928485</td>\n",
       "      <td>-5.374222</td>\n",
       "      <td>6.051902</td>\n",
       "      <td>4.222765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619270</th>\n",
       "      <td>32.040489</td>\n",
       "      <td>23.112164</td>\n",
       "      <td>19.5</td>\n",
       "      <td>81.5</td>\n",
       "      <td>10</td>\n",
       "      <td>17.413862</td>\n",
       "      <td>23.608156</td>\n",
       "      <td>31.936867</td>\n",
       "      <td>4.590051</td>\n",
       "      <td>23.643244</td>\n",
       "      <td>33.133476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.337740</td>\n",
       "      <td>33.070889</td>\n",
       "      <td>1.069597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36552 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tmax       tmin   lat   lon  month rainfall_lag1  tmin_lag1  \\\n",
       "1233506  33.500629  25.851522  24.5  83.5      7     11.457508  26.260187   \n",
       "69912    22.160629   8.690793  30.5  74.5      3      3.041445  15.788067   \n",
       "1264558  30.699596  19.973892  34.5  73.5      8           0.0  18.625856   \n",
       "1169046  33.820515  22.628618  22.5  72.5      5           0.0  23.126904   \n",
       "612102   29.371477  16.738756  36.5  74.5      9      6.417793  15.907810   \n",
       "...            ...        ...   ...   ...    ...           ...        ...   \n",
       "1086996  31.438076  21.369711  10.5  79.5      2           0.0  20.793087   \n",
       "204381   32.944904  23.809467  27.5  96.5      7      5.356512  24.088800   \n",
       "385186    8.659752   3.233021  32.5  78.5      2      6.177868   3.179184   \n",
       "8568      4.364387  -6.854029  35.5  79.5      1      5.430208  -6.226419   \n",
       "619270   32.040489  23.112164  19.5  81.5     10     17.413862  23.608156   \n",
       "\n",
       "         tmax_lag1 rainfall_lag2  tmin_lag2  tmax_lag2 rainfall_lag3  \\\n",
       "1233506  33.184647      6.314296  26.018789  32.774895     20.407169   \n",
       "69912    30.918373      4.156647  16.041580  30.595781      6.430786   \n",
       "1264558  27.753078      0.001003  19.790253  30.207409      2.366238   \n",
       "1169046  33.892773      0.047061  22.913815  31.883038           0.0   \n",
       "612102   28.610575      7.690259  16.826775  29.499233           0.0   \n",
       "...            ...           ...        ...        ...           ...   \n",
       "1086996  32.266541           0.0  18.465057  30.515810           0.0   \n",
       "204381   32.993355      2.164036  24.097441  32.973579      9.242778   \n",
       "385186    9.396719      6.813626   5.265955  11.882030      4.767539   \n",
       "8568      5.599256      4.550791  -5.436159   6.039911      4.928485   \n",
       "619270   31.936867      4.590051  23.643244  33.133476           0.0   \n",
       "\n",
       "         tmin_lag3  tmax_lag3  rainfall  \n",
       "1233506  25.597666  32.858776  4.767361  \n",
       "69912    10.608399  19.546478  4.828847  \n",
       "1264558  20.289574  30.420904   1.17993  \n",
       "1169046  22.908373  31.278032  1.917958  \n",
       "612102   14.303546  26.999653  1.624089  \n",
       "...            ...        ...       ...  \n",
       "1086996  18.030764  30.152756  4.727511  \n",
       "204381   24.689068  32.823479  2.077559  \n",
       "385186    5.560972  13.384615  3.180301  \n",
       "8568     -5.374222   6.051902  4.222765  \n",
       "619270   23.337740  33.070889  1.069597  \n",
       "\n",
       "[36552 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df['rainfall'] >= 1) & (train_df['rainfall'] <= 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192dc827",
   "metadata": {},
   "source": [
    "\n",
    "### Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d54fdd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 109.48438971541853\n",
      "Linear Regression R-squared: 0.07727972699717311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare data\n",
    "X = combined_df[['lat', 'lon', 'tmin', 'tmax']]\n",
    "y = combined_df['rainfall']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = linear_model.predict(X_test)\n",
    "print(\"Linear Regression MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Linear Regression R-squared:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebc367",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2542f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>rainfall_lag1</th>\n",
       "      <th>tmin_lag1</th>\n",
       "      <th>tmax_lag1</th>\n",
       "      <th>rainfall_lag2</th>\n",
       "      <th>tmin_lag2</th>\n",
       "      <th>tmax_lag2</th>\n",
       "      <th>rainfall_lag3</th>\n",
       "      <th>tmin_lag3</th>\n",
       "      <th>tmax_lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.000481</td>\n",
       "      <td>26.811592</td>\n",
       "      <td>24.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.997257</td>\n",
       "      <td>46.193928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.839128</td>\n",
       "      <td>45.688316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.982134</td>\n",
       "      <td>45.613052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.434790</td>\n",
       "      <td>23.616657</td>\n",
       "      <td>17.5</td>\n",
       "      <td>81.5</td>\n",
       "      <td>8</td>\n",
       "      <td>4.130811</td>\n",
       "      <td>24.045216</td>\n",
       "      <td>30.723562</td>\n",
       "      <td>16.629883</td>\n",
       "      <td>23.781025</td>\n",
       "      <td>30.715736</td>\n",
       "      <td>3.576759</td>\n",
       "      <td>22.735800</td>\n",
       "      <td>30.106403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.959087</td>\n",
       "      <td>11.998921</td>\n",
       "      <td>28.5</td>\n",
       "      <td>73.5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.223704</td>\n",
       "      <td>28.289671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.613625</td>\n",
       "      <td>25.535789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.310403</td>\n",
       "      <td>25.836740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.460081</td>\n",
       "      <td>20.127975</td>\n",
       "      <td>23.5</td>\n",
       "      <td>91.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.504341</td>\n",
       "      <td>34.566147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.393032</td>\n",
       "      <td>34.645550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.322351</td>\n",
       "      <td>35.077496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.949936</td>\n",
       "      <td>22.337227</td>\n",
       "      <td>14.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>10</td>\n",
       "      <td>27.893852</td>\n",
       "      <td>24.355722</td>\n",
       "      <td>33.198692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.487925</td>\n",
       "      <td>30.801878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.073111</td>\n",
       "      <td>29.058229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004983</th>\n",
       "      <td>27.390507</td>\n",
       "      <td>22.359585</td>\n",
       "      <td>15.5</td>\n",
       "      <td>77.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.674887</td>\n",
       "      <td>26.032665</td>\n",
       "      <td>1.513872</td>\n",
       "      <td>21.746965</td>\n",
       "      <td>26.134336</td>\n",
       "      <td>20.548386</td>\n",
       "      <td>22.873724</td>\n",
       "      <td>26.541073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004984</th>\n",
       "      <td>30.177738</td>\n",
       "      <td>24.224222</td>\n",
       "      <td>19.5</td>\n",
       "      <td>73.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.982695</td>\n",
       "      <td>32.657612</td>\n",
       "      <td>26.220745</td>\n",
       "      <td>24.828444</td>\n",
       "      <td>32.353474</td>\n",
       "      <td>12.275237</td>\n",
       "      <td>24.156969</td>\n",
       "      <td>32.357563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004985</th>\n",
       "      <td>34.371857</td>\n",
       "      <td>21.281370</td>\n",
       "      <td>13.5</td>\n",
       "      <td>75.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.976992</td>\n",
       "      <td>34.199097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.776783</td>\n",
       "      <td>35.872559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.918341</td>\n",
       "      <td>36.442924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004986</th>\n",
       "      <td>28.143435</td>\n",
       "      <td>23.871866</td>\n",
       "      <td>24.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>8</td>\n",
       "      <td>10.547924</td>\n",
       "      <td>23.711760</td>\n",
       "      <td>28.083920</td>\n",
       "      <td>26.4995</td>\n",
       "      <td>23.463823</td>\n",
       "      <td>28.536638</td>\n",
       "      <td>5.135821</td>\n",
       "      <td>23.827614</td>\n",
       "      <td>28.776018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004987</th>\n",
       "      <td>29.389229</td>\n",
       "      <td>16.569963</td>\n",
       "      <td>19.5</td>\n",
       "      <td>81.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.668039</td>\n",
       "      <td>29.324387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.130756</td>\n",
       "      <td>30.076973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.470900</td>\n",
       "      <td>30.692926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004988 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tmax       tmin   lat   lon  month rainfall_lag1  tmin_lag1  \\\n",
       "0        46.000481  26.811592  24.5  78.5      5           0.0  26.997257   \n",
       "1        30.434790  23.616657  17.5  81.5      8      4.130811  24.045216   \n",
       "2        27.959087  11.998921  28.5  73.5     12           0.0  12.223704   \n",
       "3        30.460081  20.127975  23.5  91.5      5           0.0  24.504341   \n",
       "4        30.949936  22.337227  14.5  74.5     10     27.893852  24.355722   \n",
       "...            ...        ...   ...   ...    ...           ...        ...   \n",
       "1004983  27.390507  22.359585  15.5  77.5      8           0.0  21.674887   \n",
       "1004984  30.177738  24.224222  19.5  73.5      7           0.0  24.982695   \n",
       "1004985  34.371857  21.281370  13.5  75.5      3           0.0  21.976992   \n",
       "1004986  28.143435  23.871866  24.5  79.5      8     10.547924  23.711760   \n",
       "1004987  29.389229  16.569963  19.5  81.5      2           0.0  17.668039   \n",
       "\n",
       "         tmax_lag1 rainfall_lag2  tmin_lag2  tmax_lag2 rainfall_lag3  \\\n",
       "0        46.193928           0.0  28.839128  45.688316           0.0   \n",
       "1        30.723562     16.629883  23.781025  30.715736      3.576759   \n",
       "2        28.289671           0.0  13.613625  25.535789           0.0   \n",
       "3        34.566147           0.0  23.393032  34.645550           0.0   \n",
       "4        33.198692           0.0  22.487925  30.801878           0.0   \n",
       "...            ...           ...        ...        ...           ...   \n",
       "1004983  26.032665      1.513872  21.746965  26.134336     20.548386   \n",
       "1004984  32.657612     26.220745  24.828444  32.353474     12.275237   \n",
       "1004985  34.199097           0.0  23.776783  35.872559           0.0   \n",
       "1004986  28.083920       26.4995  23.463823  28.536638      5.135821   \n",
       "1004987  29.324387           0.0  18.130756  30.076973           0.0   \n",
       "\n",
       "         tmin_lag3  tmax_lag3  \n",
       "0        28.982134  45.613052  \n",
       "1        22.735800  30.106403  \n",
       "2        13.310403  25.836740  \n",
       "3        23.322351  35.077496  \n",
       "4        21.073111  29.058229  \n",
       "...            ...        ...  \n",
       "1004983  22.873724  26.541073  \n",
       "1004984  24.156969  32.357563  \n",
       "1004985  21.918341  36.442924  \n",
       "1004986  23.827614  28.776018  \n",
       "1004987  18.470900  30.692926  \n",
       "\n",
       "[1004988 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620270e8",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "499c9f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 87.05188626268406\n",
      "Random Forest R-squared: 0.26633796410153543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Random Forest R-squared:\", r2_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3a14918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Temporal Features - Mean Squared Error: 72.53472527327952\n",
      "Random Forest with Temporal Features - R-squared: 0.38619406314045823\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Copy combined_df to avoid modifying the original data\n",
    "df = combined_df.copy()\n",
    "\n",
    "# Feature Engineering\n",
    "# Extract month and day from date\n",
    "df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "df['day'] = pd.to_datetime(df['date']).dt.day\n",
    "\n",
    "# Create lag features for rainfall, tmin, and tmax (using 1-day lag as an example)\n",
    "df['rainfall_lag1'] = df['rainfall'].shift(1)\n",
    "df['tmin_lag1'] = df['tmin'].shift(1)\n",
    "df['tmax_lag1'] = df['tmax'].shift(1)\n",
    "\n",
    "# Additional lag features (optional)\n",
    "# df['rainfall_lag2'] = df['rainfall'].shift(2)  # 2-day lag\n",
    "# df['tmin_lag2'] = df['tmin'].shift(2)\n",
    "# df['tmax_lag2'] = df['tmax'].shift(2)\n",
    "\n",
    "# Drop rows with NaN values caused by shifting (for the first row or two)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df[['lat', 'lon', 'tmin', 'tmax', 'month', 'day', 'rainfall_lag1', 'tmin_lag1', 'tmax_lag1']]\n",
    "y = df['rainfall']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest with Temporal Features - Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Random Forest with Temporal Features - R-squared:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7771ac44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting with Lag Features - Mean Squared Error: 77.99471260690511\n",
      "Gradient Boosting with Lag Features - R-squared: 0.36711030259973465\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Copy combined_df to avoid modifying the original data\n",
    "df = combined_df.copy()\n",
    "\n",
    "# Feature Engineering\n",
    "# Extract month and day from date to account for seasonality\n",
    "df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "df['day'] = pd.to_datetime(df['date']).dt.day\n",
    "\n",
    "# Create lag features for rainfall, tmin, and tmax (1-day and 2-day lags)\n",
    "df['rainfall_lag1'] = df['rainfall'].shift(1)\n",
    "df['tmin_lag1'] = df['tmin'].shift(1)\n",
    "df['tmax_lag1'] = df['tmax'].shift(1)\n",
    "\n",
    "df['rainfall_lag2'] = df['rainfall'].shift(2)\n",
    "df['tmin_lag2'] = df['tmin'].shift(2)\n",
    "df['tmax_lag2'] = df['tmax'].shift(2)\n",
    "\n",
    "# Drop rows with NaN values caused by shifting (for the first two rows in this case)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df[['lat', 'lon', 'tmin', 'tmax', 'month', 'day', \n",
    "        'rainfall_lag1', 'tmin_lag1', 'tmax_lag1', \n",
    "        'rainfall_lag2', 'tmin_lag2', 'tmax_lag2']]\n",
    "y = df['rainfall']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Gradient Boosting Regressor model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting with Lag Features - Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Gradient Boosting with Lag Features - R-squared:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b61baa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost with Lag Features and Rolling Averages - Mean Squared Error: 72.93159667576857\n",
      "XGBoost with Lag Features and Rolling Averages - R-squared: 0.3879686865545823\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Copy combined_df to avoid modifying the original data\n",
    "df = combined_df.copy()\n",
    "\n",
    "# Feature Engineering\n",
    "# Extract month and day from date to account for seasonality\n",
    "df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "df['day'] = pd.to_datetime(df['date']).dt.day\n",
    "\n",
    "# Create lag features and rolling averages for rainfall, tmin, and tmax\n",
    "df['rainfall_lag1'] = df['rainfall'].shift(1)\n",
    "df['tmin_lag1'] = df['tmin'].shift(1)\n",
    "df['tmax_lag1'] = df['tmax'].shift(1)\n",
    "\n",
    "df['rainfall_lag2'] = df['rainfall'].shift(2)\n",
    "df['tmin_lag2'] = df['tmin'].shift(2)\n",
    "df['tmax_lag2'] = df['tmax'].shift(2)\n",
    "\n",
    "# Rolling averages (3-day average)\n",
    "df['rainfall_3day_avg'] = df['rainfall'].shift(1).rolling(window=3).mean()\n",
    "df['tmin_3day_avg'] = df['tmin'].shift(1).rolling(window=3).mean()\n",
    "df['tmax_3day_avg'] = df['tmax'].shift(1).rolling(window=3).mean()\n",
    "\n",
    "# Drop rows with NaN values caused by shifting and rolling\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Ensure all features are numeric\n",
    "numeric_columns = ['rainfall_lag1', 'rainfall_lag2', 'tmin_lag1', 'tmin_lag2', \n",
    "                   'tmax_lag1', 'tmax_lag2', 'rainfall_3day_avg', \n",
    "                   'tmin_3day_avg', 'tmax_3day_avg']\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Drop any remaining rows with NaN values (if there are any left after conversion)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df[['lat', 'lon', 'tmin', 'tmax', 'month', 'day', \n",
    "        'rainfall_lag1', 'tmin_lag1', 'tmax_lag1', \n",
    "        'rainfall_lag2', 'tmin_lag2', 'tmax_lag2', \n",
    "        'rainfall_3day_avg', 'tmin_3day_avg', 'tmax_3day_avg']]\n",
    "y = df['rainfall']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "gb_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost with Lag Features and Rolling Averages - Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"XGBoost with Lag Features and Rolling Averages - R-squared:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e614b8a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rainfall'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rainfall'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(df_none \u001b[38;5;241m=\u001b[39m train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrainfall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rainfall'"
     ]
    }
   ],
   "source": [
    "len(df_none = train_df[train_df['rainfall'] <= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3b9a429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>rainfall_lag1</th>\n",
       "      <th>tmin_lag1</th>\n",
       "      <th>tmax_lag1</th>\n",
       "      <th>rainfall_lag2</th>\n",
       "      <th>tmin_lag2</th>\n",
       "      <th>tmax_lag2</th>\n",
       "      <th>rainfall_lag3</th>\n",
       "      <th>tmin_lag3</th>\n",
       "      <th>tmax_lag3</th>\n",
       "      <th>rainfall_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433849</th>\n",
       "      <td>39.035294</td>\n",
       "      <td>20.086781</td>\n",
       "      <td>21.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.347363</td>\n",
       "      <td>38.158993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.513731</td>\n",
       "      <td>37.283146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.845798</td>\n",
       "      <td>35.761120</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020281</th>\n",
       "      <td>28.124092</td>\n",
       "      <td>8.978289</td>\n",
       "      <td>28.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.901142</td>\n",
       "      <td>28.330221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.472496</td>\n",
       "      <td>28.702677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.134565</td>\n",
       "      <td>29.421640</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647816</th>\n",
       "      <td>27.643621</td>\n",
       "      <td>20.068008</td>\n",
       "      <td>10.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>11</td>\n",
       "      <td>3.182608</td>\n",
       "      <td>22.356794</td>\n",
       "      <td>30.519241</td>\n",
       "      <td>58.583172</td>\n",
       "      <td>22.098606</td>\n",
       "      <td>30.755178</td>\n",
       "      <td>8.721501</td>\n",
       "      <td>22.097355</td>\n",
       "      <td>30.525640</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067239</th>\n",
       "      <td>23.386459</td>\n",
       "      <td>7.951762</td>\n",
       "      <td>24.5</td>\n",
       "      <td>69.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.040932</td>\n",
       "      <td>22.044653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.331120</td>\n",
       "      <td>22.714642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.595883</td>\n",
       "      <td>25.130690</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109618</th>\n",
       "      <td>34.603153</td>\n",
       "      <td>17.637062</td>\n",
       "      <td>27.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.925789</td>\n",
       "      <td>34.915749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.136454</td>\n",
       "      <td>35.631111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.916739</td>\n",
       "      <td>27.527790</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806011</th>\n",
       "      <td>35.773399</td>\n",
       "      <td>17.519110</td>\n",
       "      <td>29.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.149632</td>\n",
       "      <td>39.386261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.397463</td>\n",
       "      <td>41.377182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.108980</td>\n",
       "      <td>41.571579</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137959</th>\n",
       "      <td>36.676746</td>\n",
       "      <td>25.116705</td>\n",
       "      <td>11.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.302917</td>\n",
       "      <td>33.741489</td>\n",
       "      <td>3.965574</td>\n",
       "      <td>20.317877</td>\n",
       "      <td>32.300201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.201389</td>\n",
       "      <td>31.972261</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410540</th>\n",
       "      <td>32.778442</td>\n",
       "      <td>19.468470</td>\n",
       "      <td>13.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.043310</td>\n",
       "      <td>33.969254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.795572</td>\n",
       "      <td>34.298820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.651436</td>\n",
       "      <td>33.027950</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456953</th>\n",
       "      <td>39.715446</td>\n",
       "      <td>21.961395</td>\n",
       "      <td>22.5</td>\n",
       "      <td>80.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.698277</td>\n",
       "      <td>39.242443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.648506</td>\n",
       "      <td>39.592129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.112253</td>\n",
       "      <td>39.869778</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379275</th>\n",
       "      <td>21.233063</td>\n",
       "      <td>7.773958</td>\n",
       "      <td>27.5</td>\n",
       "      <td>88.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.312551</td>\n",
       "      <td>16.779535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.169916</td>\n",
       "      <td>15.747324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.866889</td>\n",
       "      <td>16.716753</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406274 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tmax       tmin   lat   lon  month rainfall_lag1  tmin_lag1  \\\n",
       "433849   39.035294  20.086781  21.5  71.5      3           0.0  20.347363   \n",
       "1020281  28.124092   8.978289  28.5  76.5     11           0.0   8.901142   \n",
       "647816   27.643621  20.068008  10.5  76.5     11      3.182608  22.356794   \n",
       "1067239  23.386459   7.951762  24.5  69.5      1           0.0  11.040932   \n",
       "1109618  34.603153  17.637062  27.5  71.5      2           0.0  17.925789   \n",
       "...            ...        ...   ...   ...    ...           ...        ...   \n",
       "806011   35.773399  17.519110  29.5  78.5      4           0.0  20.149632   \n",
       "1137959  36.676746  25.116705  11.5  78.5      3           0.0  21.302917   \n",
       "410540   32.778442  19.468470  13.5  74.5      3           0.0  20.043310   \n",
       "456953   39.715446  21.961395  22.5  80.5      4           0.0  21.698277   \n",
       "379275   21.233063   7.773958  27.5  88.5      1           0.0   7.312551   \n",
       "\n",
       "         tmax_lag1 rainfall_lag2  tmin_lag2  tmax_lag2 rainfall_lag3  \\\n",
       "433849   38.158993           0.0  20.513731  37.283146           0.0   \n",
       "1020281  28.330221           0.0   8.472496  28.702677           0.0   \n",
       "647816   30.519241     58.583172  22.098606  30.755178      8.721501   \n",
       "1067239  22.044653           0.0  11.331120  22.714642           0.0   \n",
       "1109618  34.915749           0.0  18.136454  35.631111           0.0   \n",
       "...            ...           ...        ...        ...           ...   \n",
       "806011   39.386261           0.0  21.397463  41.377182           0.0   \n",
       "1137959  33.741489      3.965574  20.317877  32.300201           0.0   \n",
       "410540   33.969254           0.0  17.795572  34.298820           0.0   \n",
       "456953   39.242443           0.0  21.648506  39.592129           0.0   \n",
       "379275   16.779535           0.0   7.169916  15.747324           0.0   \n",
       "\n",
       "         tmin_lag3  tmax_lag3 rainfall_category  \n",
       "433849   23.845798  35.761120              none  \n",
       "1020281   9.134565  29.421640              none  \n",
       "647816   22.097355  30.525640          moderate  \n",
       "1067239  14.595883  25.130690              none  \n",
       "1109618  13.916739  27.527790              none  \n",
       "...            ...        ...               ...  \n",
       "806011   21.108980  41.571579              none  \n",
       "1137959  21.201389  31.972261              none  \n",
       "410540   17.651436  33.027950              none  \n",
       "456953   22.112253  39.869778              none  \n",
       "379275    6.866889  16.716753              none  \n",
       "\n",
       "[406274 rows x 15 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041273e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
